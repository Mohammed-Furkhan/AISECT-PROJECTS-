{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pDamzS1BUjdS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_simplified = pd.read_csv('/content/Clean_Dataset.csv')"
      ],
      "metadata": {
        "id": "0QM-R7r0UydO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dependent_variable = dataset_simplified[['class']]"
      ],
      "metadata": {
        "id": "7iz1dsNOVCwy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "independent_variables = dataset_simplified.drop(['class', 'Unnamed: 0', 'flight'], axis=1)"
      ],
      "metadata": {
        "id": "f3EeUDiuVOYV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "independent_variables_encoded = pd.get_dummies(independent_variables, drop_first=True)"
      ],
      "metadata": {
        "id": "WzIIZ0JUVRgZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "independent_variables_encoded['duration_x_days_left'] = independent_variables_encoded['duration'] * independent_variables_encoded['days_left']"
      ],
      "metadata": {
        "id": "ybyNGGx8VVdQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'price' in independent_variables_encoded.columns: # Check if 'price' is still in features after dropping 'class'\n",
        "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "    # Ensure the columns exist before transforming\n",
        "    cols_for_poly = ['duration', 'price']\n",
        "    existing_cols_for_poly = [col for col in cols_for_poly if col in independent_variables_encoded.columns]\n",
        "    if existing_cols_for_poly:\n",
        "        # Drop rows with NaN values before applying polynomial features\n",
        "        independent_variables_encoded_cleaned = independent_variables_encoded.dropna(subset=existing_cols_for_poly)\n",
        "        poly_features = poly.fit_transform(independent_variables_encoded_cleaned[existing_cols_for_poly])\n",
        "\n",
        "        # Create a DataFrame from the polynomial features\n",
        "        poly_feature_names = poly.get_feature_names_out(existing_cols_for_poly)\n",
        "        poly_df = pd.DataFrame(poly_features, columns=poly_feature_names, index=independent_variables_encoded_cleaned.index)\n",
        "\n",
        "        # Concatenate the new polynomial features\n",
        "        independent_variables_encoded = pd.concat([independent_variables_encoded_cleaned, poly_df], axis=1)\n",
        "    else:\n",
        "        print(\"Columns for polynomial features ('duration', 'price') not found after preprocessing.\")\n",
        "else:\n",
        "    print(\"'price' column not found in independent variables after dropping 'class'. Skipping polynomial features for 'price'.\")\n",
        "    # If 'price' is not in the independent variables, we can still create polynomial features for 'duration' if it exists\n",
        "    if 'duration' in independent_variables_encoded.columns:\n",
        "         # Drop rows with NaN values before applying polynomial features\n",
        "         independent_variables_encoded_cleaned = independent_variables_encoded.dropna(subset=['duration'])\n",
        "         poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "         poly_features = poly.fit_transform(independent_variables_encoded_cleaned[['duration']])\n",
        "         poly_feature_names = poly.get_feature_names_out(['duration'])\n",
        "         poly_df = pd.DataFrame(poly_features, columns=poly_feature_names, index=independent_variables_encoded_cleaned.index)\n",
        "         independent_variables_encoded = pd.concat([independent_variables_encoded_cleaned, poly_df], axis=1)"
      ],
      "metadata": {
        "id": "jLsRTBnpVaMI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the dependent variable has the same index as the independent variables after dropping rows\n",
        "dependent_variable_aligned = dependent_variable.loc[independent_variables_encoded.index]\n",
        "\n",
        "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(independent_variables_encoded, dependent_variable_aligned.values.ravel(), test_size=0.30, random_state=0)"
      ],
      "metadata": {
        "id": "O5-wxJqeVszc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0d1b4d7",
        "outputId": "28c0a66e-0f69-44ee-9032-38ba4b8ed14e"
      },
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Initialize RFE with a Decision Tree classifier and the number of features to select\n",
        "# You might want to experiment with the number of features to select\n",
        "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=10) # Example: selecting 10 features\n",
        "\n",
        "# Fit RFE to the training data to select the most important features\n",
        "rfe.fit(X_train_cls, y_train_cls)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features_rfe = X_train_cls.columns[rfe.support_]\n",
        "\n",
        "print(\"Selected features by RFE:\")\n",
        "print(list(selected_features_rfe))\n",
        "\n",
        "# Transform the training and testing data to include only the selected features\n",
        "X_train_cls_rfe = rfe.transform(X_train_cls)\n",
        "X_test_cls_rfe = rfe.transform(X_test_cls)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features by RFE:\n",
            "['days_left', 'price', 'airline_Indigo', 'source_city_Chennai', 'source_city_Hyderabad', 'source_city_Kolkata', 'price', 'duration^2', 'duration price', 'price^2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
        "\n",
        "print(\"--- Decision Tree Classifier ---\")\n",
        "classifier_dt_simplified = DecisionTreeClassifier(random_state=0)\n",
        "classifier_dt_simplified.fit(X_train_cls_rfe, y_train_cls)\n",
        "y_pred_dt = classifier_dt_simplified.predict(X_test_cls_rfe)\n",
        "accuracy_dt = accuracy_score(y_test_cls, y_pred_dt)\n",
        "f1_dt = f1_score(y_test_cls, y_pred_dt, average='weighted') # Use weighted average for multiclass\n",
        "recall_dt = recall_score(y_test_cls, y_pred_dt, average='weighted') # Use weighted average for multiclass\n",
        "print(\"Accuracy:\", accuracy_dt)\n",
        "print(\"F1 Score:\", f1_dt)\n",
        "print(\"Recall:\", recall_dt)\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Logistic Regression\n",
        "print(\"--- Logistic Regression ---\")\n",
        "classifier_lr = LogisticRegression(random_state=0, max_iter=1000)\n",
        "classifier_lr.fit(X_train_cls_rfe, y_train_cls)\n",
        "y_pred_lr = classifier_lr.predict(X_test_cls_rfe)\n",
        "accuracy_lr = accuracy_score(y_test_cls, y_pred_lr)\n",
        "f1_lr = f1_score(y_test_cls, y_pred_lr, average='weighted') # Use weighted average for multiclass\n",
        "recall_lr = recall_score(y_test_cls, y_pred_lr, average='weighted') # Use weighted average for multiclass\n",
        "print(\"Accuracy:\", accuracy_lr)\n",
        "print(\"F1 Score:\", f1_lr)\n",
        "print(\"Recall:\", recall_lr)\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Random Forest Classifier\n",
        "print(\"--- Random Forest Classifier ---\")\n",
        "classifier_rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "classifier_rf.fit(X_train_cls_rfe, y_train_cls)\n",
        "y_pred_rf = classifier_rf.predict(X_test_cls_rfe)\n",
        "accuracy_rf = accuracy_score(y_test_cls, y_pred_rf)\n",
        "f1_rf = f1_score(y_test_cls, y_pred_rf, average='weighted') # Use weighted average for multiclass\n",
        "recall_rf = recall_score(y_test_cls, y_pred_rf, average='weighted') # Use weighted average for multiclass\n",
        "print(\"Accuracy:\", accuracy_rf)\n",
        "print(\"F1 Score:\", f1_rf)\n",
        "print(\"Recall:\", recall_rf)\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Support Vector Machine (SVM) Classifier\n",
        "print(\"--- Support Vector Machine (SVM) Classifier ---\")\n",
        "# Note: SVMs can be computationally expensive on large datasets\n",
        "classifier_svm = SVC(random_state=0)\n",
        "classifier_svm.fit(X_train_cls_rfe, y_train_cls)\n",
        "y_pred_svm = classifier_svm.predict(X_test_cls_rfe)\n",
        "accuracy_svm = accuracy_score(y_test_cls, y_pred_svm)\n",
        "f1_svm = f1_score(y_test_cls, y_pred_svm, average='weighted') # Use weighted average for multiclass\n",
        "recall_svm = recall_score(y_test_cls, y_pred_svm, average='weighted') # Use weighted average for multiclass\n",
        "print(\"Accuracy:\", accuracy_svm)\n",
        "print(\"F1 Score:\", f1_svm)\n",
        "print(\"Recall:\", recall_svm)\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzE6tW1BV2Z1",
        "outputId": "8f71bada-19ec-4f92-af70-7431a306cabe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Decision Tree Classifier ---\n",
            "Accuracy: 0.9998905024568511\n",
            "F1 Score: 0.999890518682968\n",
            "Recall: 0.9998905024568511\n",
            "------------------------------\n",
            "--- Logistic Regression ---\n",
            "Accuracy: 0.9969066944060443\n",
            "F1 Score: 0.9969090963099243\n",
            "Recall: 0.9969066944060443\n",
            "------------------------------\n",
            "--- Random Forest Classifier ---\n",
            "Accuracy: 0.9999178768426383\n",
            "F1 Score: 0.9999178859708641\n",
            "Recall: 0.9999178768426383\n",
            "------------------------------\n",
            "--- Support Vector Machine (SVM) Classifier ---\n",
            "Accuracy: 0.9899399132231971\n",
            "F1 Score: 0.9898970430914833\n",
            "Recall: 0.9899399132231971\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ]
}